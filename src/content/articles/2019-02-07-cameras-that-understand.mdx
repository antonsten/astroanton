---
slug: cameras-that-understand
title: "Cameras that understand"
description: A short reflection on user experience and design.
date: 2019-02-07
readingTime: 2
---

>One of the desire paths of the smartphone camera is that since we have it with us all the time and we can take unlimited pictures for free, and have them instantly, we don’t just take more pictures of our children and dogs but also pictures of things that we’d never have taken pictures of before. We take pictures of posters and books and things we might want to buy - we take pictures of recipes, catalogues, conference schedules, train timetables (Americans, ask a foreigner) and fliers. The smartphone image sensor has become a notebook. (Something similar has happened with smartphone screenshots, another desire path that no-one thought would become a normal consumer behavior.)
<br /><br />
Machine learning means that the computer will be able to unlock a lot of this. If there's a date in this picture, what might that mean? Does this look like a recipe? Is there a book in this photo and can we match it to an Amazon listing? Can we match the handbag to Net a Porter? And so you can imagine a suggestion from your phone: “do you want to add the date in this photo to your diary?” in much the same way that today email programs extract flights or meetings or contact details from emails.
**<a href="https://www.ben-evans.com/benedictevans/2019/2/5/cameras-that-understand">Ben Evans: Cameras that understand</a>**

The above excerpt is just a tiny fraction and the entire post is great reading and thinking by Ben. I've been thinking about voice controlled systems lately too, <a href="/newsletter">expect a longer post</a> on that topic on Monday!